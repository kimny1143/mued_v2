/**
 * HLA PoC - ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãƒ†ã‚¹ãƒˆ
 * gpt-5-mini vs gpt-4.1-nano
 */

import * as fs from 'fs';

// ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
function loadEnv() {
  const envPath = '/Users/kimny/Dropbox/_DevProjects/mued/mued_v2/.env.local';
  if (fs.existsSync(envPath)) {
    const content = fs.readFileSync(envPath, 'utf-8');
    content.split('\n').forEach((line) => {
      const match = line.match(/^([^=]+)=(.*)$/);
      if (match && !process.env[match[1]]) {
        process.env[match[1]] = match[2];
      }
    });
  }
}
loadEnv();

const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
if (!OPENAI_API_KEY) {
  console.error('âŒ OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“');
  process.exit(1);
}

// ãƒ†ã‚¹ãƒˆå¯¾è±¡ãƒ¢ãƒ‡ãƒ«
const MODELS = ['gpt-4.1-nano'];

// ãƒ†ã‚¹ãƒˆå…¥åŠ›ï¼ˆ1ã¤ã ã‘ã§æ¯”è¼ƒï¼‰
const testInput = `
ãˆãƒ¼ã£ã¨ã€ã€ã€
ã“ã“ã•ã‚ã€ã€ã€Dm7ã‹ã‚‰ã•ã‚ã€ã€ã€G7ã§ã€ã€ã€ã‚“ãƒ¼æ™®é€šã™ãŽã‚‹ã‹ãªã‚
ã„ã‚„ã¾ã‚ã€ã“ã‚Œã¯ã“ã‚Œã§
ã‚ã€ãƒ™ãƒ¼ã‚¹ã€ãƒ™ãƒ¼ã‚¹ã‚ã¨ã§ã­
ã†ã‚ã€œã€œã€œã¾ãŸè½ã¡ãŸã€ã“ã®ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã€ã¾ã˜ã§ã€ã€ã€
ã‚“ãƒ¼ãƒ¼ãƒ¼
ã‚ã€ãã†ã ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã€ã€ã€BPMã€ã€ã€Spotifyã®ã‚„ã¤ã€èª¿ã¹ãªã„ã¨
ã“ã“ã®ã‚³ãƒ³ãƒ—ã•ã‚ã€ã€ã€ã‚¢ã‚¿ãƒƒã‚¯ã€ã€ã€æ—©ã„ã¨ã•ã‚ã€ãƒ‘ãƒ³ãƒãªããªã‚‹ã‚“ã ã‚ˆã­
ã“ã‚Œå‰ã‚‚ã‚„ã£ãŸãªã€ã€ã€
æ˜Žæ—¥ã¾ã§ã€ãƒ‰ãƒ©ãƒ ã€ã€ã€ã‚„ã‚“ãªã„ã¨ãªã‚
ã‚ã€œã€œã€œãƒ¢ãƒãƒ™ã€ã€ã€ã¾ã‚ã„ã„ã‹
ã‚µãƒ“ã€3åº¦ä¸Šã€ã€ã€ãƒãƒ¢ã‚Šã€ã€ã€åŽšããªã‚Šãã†
`;

const HLA_SYSTEM_PROMPT = `éŸ³æ¥½åˆ¶ä½œè€…ã®æ€è€ƒãƒ­ã‚°ã‚’æ•´ç†ã—ã¦ãã ã•ã„ã€‚

## å…¥åŠ›ã®ç‰¹å¾´
- æ–­ç‰‡çš„ã§æ–‡æ³•ä¸å®Œå…¨ï¼ˆã€Œã€ã€ã€ã€ã€Œã€œã€œã€œã€å¤šã„ï¼‰
- æŒ‡ç¤ºèªžå¤šã„ï¼ˆã€Œã“ã“ã€ã€Œã“ã‚Œã€ï¼‰
- æ„Ÿå˜†è©žã®ã¿ã®è¡Œã‚ã‚Šï¼ˆã‚¹ã‚­ãƒƒãƒ—å¯¾è±¡ï¼‰

## ã‚«ãƒ†ã‚´ãƒªåˆ†é¡žï¼ˆã§ãã‚‹ã ã‘å¤šãæ‹¾ã†ï¼‰
- idea: ã€Œã€œã‹ã‚‚ã€ã€Œã€œã—ãŸã‚‰ã€ã€Œã€œã‚ã‚Šã ãªã€â†’ ã‚¢ã‚¤ãƒ‡ã‚¢
- todo: ã€Œã€œã—ãªã„ã¨ã€ã€Œæ˜Žæ—¥ã¾ã§ã€ã€Œã‚„ã‚“ãªã„ã¨ã€â†’ ã‚¿ã‚¹ã‚¯
- tips: ã€Œã€œãªã‚‹ã‚“ã ã‚ˆã­ã€ã€Œå‰ã‚‚ã‚„ã£ãŸã€â†’ å­¦ã³ãƒ»çµŒé¨“
- frustration: ã€Œã‚‚ã†ã€ã€Œãªã‚“ã§ã€ã€Œãƒžã‚¸ã§ã€ã€Œãƒ€ãƒ¡ã ã€ã€Œã†ã‚ã€œã€â†’ ä¸æº€

## é‡è¦ãƒ«ãƒ¼ãƒ«
1. æ„Ÿå˜†è©žã®ã¿ï¼ˆã€Œã‚“ãƒ¼ãƒ¼ãƒ¼ã€ã€Œã‚ã€œã€œã€å˜ç‹¬ï¼‰ã¯ã‚¹ã‚­ãƒƒãƒ—
2. æ„å‘³ã‚ã‚‹ç™ºè¨€ã¯ã™ã¹ã¦æ‹¾ã†ï¼ˆ4ã€œ10å€‹ç¨‹åº¦ï¼‰
3. å…·ä½“çš„å†…å®¹ã‚’æ®‹ã™ï¼ˆDm7, G7, ã‚³ãƒ³ãƒ—, BPMç­‰ï¼‰
4. 1æ–‡ã«è¤‡æ•°ã‚«ãƒ†ã‚´ãƒªæ··åœ¨â†’ä¸»è¦ãªã‚‚ã®1ã¤é¸æŠž

## å‡ºåŠ›JSON
{
  "items": [{ "category": "idea|todo|tips|frustration", "content": "å…·ä½“çš„å†…å®¹" }],
  "summary": { "mainFocus": "å…·ä½“çš„ã«", "mood": "productive|creative|frustrated|learning|mixed" },
  "meta": { "totalItems": N, "categoryCounts": {"idea":N,"todo":N,"tips":N,"frustration":N} }
}`;

async function callOpenAI(model, prompt) {
  // gpt-5ç³»ã¯æŽ¨è«–ãƒ¢ãƒ‡ãƒ«ãªã®ã§ temperature, max_tokens ãŒä½¿ãˆãªã„
  const isGpt5 = model.startsWith('gpt-5');

  const body = {
    model: model,
    messages: [{ role: 'user', content: prompt }],
  };

  if (isGpt5) {
    body.max_completion_tokens = 1500;
    // temperature ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ(1)ã®ã¿
  } else {
    body.temperature = 0.3;
    body.max_tokens = 1500;
  }

  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${OPENAI_API_KEY}`,
    },
    body: JSON.stringify(body),
  });

  if (!response.ok) {
    const error = await response.text();
    throw new Error(`${model}: ${response.status} - ${error}`);
  }

  const data = await response.json();
  return {
    content: data.choices[0].message.content,
    usage: data.usage,
  };
}

function parseJSON(raw) {
  const jsonMatch = raw.match(/```json\s*([\s\S]*?)\s*```/) || raw.match(/(\{[\s\S]*\})/);
  if (!jsonMatch) return null;
  try {
    return JSON.parse(jsonMatch[1]);
  } catch {
    return null;
  }
}

async function testModel(model) {
  console.log(`\n${'='.repeat(50)}`);
  console.log(`ðŸ”„ ãƒ†ã‚¹ãƒˆ: ${model}`);
  console.log('='.repeat(50));

  const prompt = `${HLA_SYSTEM_PROMPT}\n\nå…¥åŠ›:\n\`\`\`\n${testInput}\n\`\`\``;
  const startTime = Date.now();

  try {
    const result = await callOpenAI(model, prompt);
    const elapsed = Date.now() - startTime;

    console.log(`â±ï¸  å‡¦ç†æ™‚é–“: ${elapsed}ms`);
    console.log(`ðŸ“Š ãƒˆãƒ¼ã‚¯ãƒ³: å…¥åŠ›=${result.usage.prompt_tokens}, å‡ºåŠ›=${result.usage.completion_tokens}, åˆè¨ˆ=${result.usage.total_tokens}`);

    const parsed = parseJSON(result.content);
    if (parsed) {
      console.log(`âœ… JSONè§£æžæˆåŠŸ`);
      console.log(`   itemsæ•°: ${parsed.items?.length || 0}`);
      console.log(`   mood: ${parsed.summary?.mood || 'N/A'}`);
      console.log(`   ã‚«ãƒ†ã‚´ãƒª: ${JSON.stringify(parsed.meta?.categoryCounts || {})}`);

      // å“è³ªãƒã‚§ãƒƒã‚¯
      const hasSpecificContent = parsed.items?.some(item =>
        item.content.includes('Dm7') ||
        item.content.includes('G7') ||
        item.content.includes('ã‚³ãƒ³ãƒ—') ||
        item.content.includes('BPM')
      );
      console.log(`   å…·ä½“æ€§ä¿æŒ: ${hasSpecificContent ? 'âœ…' : 'âŒ'}`);

      return { model, elapsed, success: true, parsed, usage: result.usage };
    } else {
      console.log(`âŒ JSONè§£æžå¤±æ•—`);
      return { model, elapsed, success: false, raw: result.content };
    }
  } catch (error) {
    console.log(`âŒ ã‚¨ãƒ©ãƒ¼: ${error.message}`);
    return { model, elapsed: 0, success: false, error: error.message };
  }
}

async function main() {
  console.log('ðŸš€ ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãƒ†ã‚¹ãƒˆé–‹å§‹\n');
  console.log('æ¯”è¼ƒãƒ¢ãƒ‡ãƒ«:', MODELS.join(' vs '));

  const results = [];

  for (const model of MODELS) {
    const result = await testModel(model);
    results.push(result);
    // ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
    await new Promise(r => setTimeout(r, 2000));
  }

  // ã‚µãƒžãƒªãƒ¼
  console.log('\n' + '='.repeat(50));
  console.log('ðŸ“Š æ¯”è¼ƒçµæžœã‚µãƒžãƒªãƒ¼');
  console.log('='.repeat(50));

  console.log('\n| ãƒ¢ãƒ‡ãƒ« | å‡¦ç†æ™‚é–“ | ãƒˆãƒ¼ã‚¯ãƒ³ | æˆåŠŸ |');
  console.log('|--------|----------|----------|------|');
  for (const r of results) {
    const time = r.elapsed ? `${r.elapsed}ms` : 'N/A';
    const tokens = r.usage ? r.usage.total_tokens : 'N/A';
    const status = r.success ? 'âœ…' : 'âŒ';
    console.log(`| ${r.model} | ${time} | ${tokens} | ${status} |`);
  }

  // å‹è€…åˆ¤å®š
  const successful = results.filter(r => r.success);
  if (successful.length >= 2) {
    const fastest = successful.reduce((a, b) => a.elapsed < b.elapsed ? a : b);
    console.log(`\nðŸ† é€Ÿåº¦å‹è€…: ${fastest.model} (${fastest.elapsed}ms)`);
  }
}

main();
