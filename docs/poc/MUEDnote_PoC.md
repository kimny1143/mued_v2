
“MUEDnoteという企画がほんとに成立するかを検証するPoC」** 

---

## 1. PoCの目的整理（何を証明したいか）

MUEDnoteで検証したいコア仮説はざっくりこの3つだと思う。

1. **行動仮説**
   ユーザーは、制作のたびに「Session + 一言メモ + AIの質問に回答する」運用を“ダルくない負荷”で続けてくれるか。

2. **価値仮説**
   AIインタビューで引き出したQ&Aログは

   * 本人にとって「振り返り・上達」に役立つ
   * 講師／第三者にとって「指導・フィードバック」に使える
     という“ちゃんとした価値”があるか。

3. **データ資産仮説**
   Session/Interviewログは、将来の

   * 弱点分析
   * 自動教材生成
     の“まともな学習データ”になりうるか。

この3つがYESなら、「ログベース教材路線でMUEDを進める」という事業計画側の判断が正当化される、って位置づけ。

---

## 2. PoCの検証観点（評価軸）

LITRONでやってるPoCフレームに寄せると、観点はこんな感じで整理できる。

1. **業務適合性**

   * 「Sessionを切る」「短いメモを書く」「質問に答える」という流れが、
     DTM制作者の日常フローに自然に乗るか。
2. **AI品質**

   * 生成される質問が「その場の作業」にちゃんと紐づいているか
   * 抽象的すぎないか／理論ガチすぎないか
3. **ユーザー価値・継続性**

   * 何度か使ったあとに「これ、続けたい」と思えるか
   * 振り返り画面を見たときに「自分の癖が見える」実感があるか
4. **データ利用可能性**

   * ログを第三者が見たときに「この人の詰まりポイントがだいたい分かる」レベルか
   * 教材生成の素体として、情報の粒度と言語が足りているか

---

## 3. PoC対象業務・スコープ

### 対象ユーザー（最低でもこの2セグメント）

* **個人DTMer（趣味〜セミプロ）**：5〜8人
* **講師 or プロ作曲家（あなた含むでもOK）**：2〜3人

まずは **日本語のみ・テキストベースMVP版**（今の設計書そのまま）に絞る。

### 対象シナリオ

1. **新規曲制作セッション**

   * Aメロ作り
   * サビのコードいじり
   * ミックス調整 など

2. **既存曲のブラッシュアップセッション**

   * 既存デモの修正
   * 提出前の最終調整

各ユーザーに
**「最低10セッション」**くらいやってもらう（1〜2週間想定）。

---

## 4. PoCで使うMUEDnote機能（MVPに限定）

計画書・技術設計書にある **Phase 1.2〜1.4あたり** を“PoC用MVP”として切り出すイメージ。

使うのはこの範囲で十分：

1. **Session作成**

   * type, title, userShortNote（1〜2行）入力

2. **MVP Analyzer（テキスト推定版）**

   * focusArea（harmony/melody/mix/感情など）
   * intentHypothesis（「落ち着かせようとしている」等）生成

3. **Interviewer LLM + RAG（小規模）**

   * 質問テンプレ + 過去Q&Aから2〜3問生成

4. **Q&A保存 + 簡易振り返り画面**

   * タイムラインでSessionとQ&Aを並べて見れる程度

**DAWメタデータ・MIDI/WAV解析はPoC範囲外**にする。
今のPoCの問いは「テキストだけでも成立するか？」なので、ここをまず固める。

---

## 5. 評価セットの作り方（LITRON的に）

### 5.1 質問生成品質の評価セット

各ユーザーから実際の **userShortNote + Session type** を10件ずつ集める。
それに対して、MUEDnoteが出した質問を、あなたか講師側で採点。

評価軸（5段階とかでOK）：

* 関連度：今やってる作業に“ちゃんと刺さっているか”
* 筆のノリ：答えやすいか（抽象すぎ／固すぎになってないか）
* 深度：浅すぎず、重すぎず、ちょうどいいか

**合格ライン例：**

* 平均スコア 3.5/5 以上
* 「完全にズレてる・聞かれても困る」質問の割合が10%未満

---

### 5.2 行動・継続性の評価

ユーザー1人あたり **10セッション**を依頼しておいて、実績値を見る。

* 実際に作成されたSession数（平均）
* 1 Sessionあたりの回答完了率（2〜3問のうち何問答えたか）
* 2回目以降も自発的に使ったか（「言われたからやった」感かどうかヒアリング）

**合格ラインの例：**

* 10セッション中、実施7以上（70%）
* 1セッションの回答率 70%以上
* インタビュー後のコメントで
  「途中で面倒になった」が多数 → NG
  「答えてみたら頭が整理された」が一定数 → OK

---

### 5.3 “ログとしての価値”評価

ここはあなたの目と、信頼できる講師1人くらいの目で見るのが良さそう。

手順イメージ：

1. ユーザーAのSession + Q&Aを **10セッション分だけ**渡す

2. それだけ見て、次の3つを判断してもらう：

   * この人が**どこでよく詰まるタイプか**（例：サビ前、イントロの尺感 etc）
   * この人の**強みっぽいところ**（例：メロは早いけどコードで悩みがち）
   * 次のレッスンで**何をテーマにすべきか**

3. レビュー後に「本人の自己申告」と照らし合わせてズレを確認

ここで
「ログがあれば、初対面でもだいたい診断できる」
まで行ければ、事業計画で書いてる“教育側の価値”はほぼ証明できる。

---

## 6. PoCの実行ステップ（ざっくりタイムライン）

1. **Week 0：仮説と指標の固定**

   * 上で書いた3つの仮説＆評価項目を1枚にまとめる
2. **Week 1：MVP機能をPoCレベルで固める**

   * Session作成 → Analyzer → 質問生成 → 回答 → 振り返り
     のラインだけ動く状態にする（UIは雑でもOK）
3. **Week 2〜3：テストユーザー募集＆オンボーディング**

   * あなたの周辺のDTMer/生徒/講師に声かけて8〜10人
   * 使い方を軽くレクチャー（オンラインでもテキストでも可）
4. **Week 3〜4：PoC本番**

   * 各ユーザーに「1〜2週間で10セッション」チャレンジを依頼
   * ログ・回答率を自動集計
5. **Week 4〜5：評価・ふりかえり**

   * 質問品質の採点
   * 行動データ（セッション数・回答率）の集計
   * ログを第三者が読んで“診断ごっこ”してみる

---

## 7. PoCの合否判定イメージ

ざっくりだけど、こんな感じで線を引ける。

* **◎（突き抜け）**

  * ユーザーが自発的に使い続けたいと言う
  * 質問の関連度スコア高い
  * 講師目線で「これあるとレッスンめちゃ楽」とはっきり言われる

* **◯（行ける）**

  * 一応使えるし、改善ポイントも見えた
    → 質問テンプレ・UIの改善で十分勝負できそう

* **△（方向転換検討）**

  * 記録はされるが、質問が邪魔・鬱陶しいと言われがち
    → 「AI質問なしの“制作日報アプリ”路線」に寄せる選択肢もあり

* **✕（撤退or統合）**

  * セッションがそもそも貯まらない / 使うモチベが上がらない
    → MUEDnoteはMUED本体のサブ機能として溶かす判断

この判定結果が、そのまま事業計画に書いてある
「MUED全体の方向性を決めるためのPoC」の答えになる感じだね。

---

ここまで決めておけば、あとは
「評価セット（質問の採点表）」と
「テスター向けの簡易マニュアル」作ればPoC回せる状態だと思う。
