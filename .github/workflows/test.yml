# Optimized CI Pipeline for MUED LMS v2
# This workflow implements the recommendations from docs/architecture/ci-cd-analysis-and-fixes.md

name: CI Pipeline (Optimized)

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

env:
  NODE_VERSION: '20'

# Cancel in-progress runs for the same branch
concurrency:
  group: ci-${{ github.ref }}
  cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}

jobs:
  # ============================================
  # STAGE 1: Fast Validation (< 1 minute)
  # ============================================
  validate:
    name: Fast Validation
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js with cache
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies (cached)
        run: npm ci --prefer-offline --no-audit

      - name: TypeScript check
        run: npx tsc --noEmit

      - name: ESLint (errors only)
        run: npm run lint -- --quiet
        continue-on-error: true

  # ============================================
  # STAGE 2: Core Tests (2-3 minutes, parallel)
  # ============================================
  test:
    name: Test (${{ matrix.suite }})
    needs: validate
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        suite: [unit, components, integration]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js with cache
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies (cached)
        run: npm ci --prefer-offline --no-audit

      - name: Run ${{ matrix.suite }} tests
        run: npm run test:${{ matrix.suite }}

      - name: Upload coverage to Codecov
        if: matrix.suite == 'unit' || matrix.suite == 'integration'
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage/lcov.info
          flags: ${{ matrix.suite }}
          name: ${{ matrix.suite }}-coverage

  # ============================================
  # STAGE 3: Build Verification (2-3 minutes)
  # ============================================
  build:
    name: Build Application
    needs: validate
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js with cache
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies (cached)
        run: npm ci --prefer-offline --no-audit

      - name: Build Next.js application
        run: npm run build
        env:
          # Mock environment variables for build
          DATABASE_URL: "postgresql://build:build@localhost:5432/build"
          NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY: ${{ secrets.CLERK_TEST_PUBLISHABLE_KEY || 'pk_test_build' }}
          CLERK_SECRET_KEY: ${{ secrets.CLERK_TEST_SECRET_KEY || 'sk_test_build' }}
          CLERK_WEBHOOK_SECRET: "whsec_mock_webhook_secret"
          NEXT_PUBLIC_CLERK_SIGN_IN_URL: "/sign-in"
          NEXT_PUBLIC_CLERK_SIGN_UP_URL: "/sign-up"
          NEXT_PUBLIC_CLERK_AFTER_SIGN_IN_URL: "/dashboard"
          NEXT_PUBLIC_CLERK_AFTER_SIGN_UP_URL: "/dashboard"
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY || 'sk-mock-openai-key-for-build-only' }}
          OPENAI_MODEL: "gpt-4"
          OPENAI_MAX_TOKENS: "2000"
          STRIPE_SECRET_KEY: ${{ secrets.STRIPE_SECRET_KEY || 'sk_test_mock_stripe_key_for_build' }}
          STRIPE_WEBHOOK_SECRET: "whsec_mock_stripe_webhook"
          NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY: "pk_test_mock_stripe_publishable"
          NEXT_PUBLIC_STRIPE_PRICE_STARTER: "price_mock_starter"
          NEXT_PUBLIC_STRIPE_PRICE_BASIC: "price_mock_basic"
          NEXT_PUBLIC_STRIPE_PRICE_PREMIUM: "price_mock_premium"
          RESEND_API_KEY: "re_mock_resend_api_key"
          NEXT_PUBLIC_APP_URL: "http://localhost:3000"
          FIGMA_ACCESS_TOKEN: "figd_mock_figma_token"

      - name: Verify build output
        run: |
          echo "Checking build output..."
          if [ ! -d ".next" ]; then
            echo "âŒ ERROR: .next directory not found!"
            exit 1
          fi
          echo "âœ… .next directory exists"
          ls -la .next/
          echo ""
          echo "Directory size:"
          du -sh .next/

      - name: Create build archive
        run: |
          echo "Creating tar archive to preserve all filenames..."
          tar -czf build-output.tar.gz .next
          ls -lh build-output.tar.gz

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-output
          path: build-output.tar.gz
          retention-days: 1
          if-no-files-found: error

  # ============================================
  # STAGE 4: E2E Tests (PR only, 5-10 minutes)
  # ============================================
  e2e:
    name: E2E Tests
    if: github.event_name == 'pull_request'
    needs: [validate, build]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js with cache
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies (cached)
        run: npm ci --prefer-offline --no-audit

      - name: Install Playwright browsers
        run: npx playwright install --with-deps chromium

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-output
          path: .

      - name: Extract build artifacts
        run: |
          echo "Extracting build archive..."
          tar -xzf build-output.tar.gz
          rm build-output.tar.gz
          ls -la .next/

      - name: Detect changed files and select tests
        id: detect-changes
        run: |
          echo "Detecting changed files to determine which E2E tests to run..."
          git fetch origin ${{ github.base_ref }}
          CHANGED_FILES=$(git diff --name-only origin/${{ github.base_ref }}...HEAD)
          echo "Changed files:"
          echo "$CHANGED_FILES"
          echo ""

          # Determine which test files to run based on changed files
          TEST_FILES=""
          RUN_ALL=false

          # Check for documentation-only changes (skip all E2E tests)
          if echo "$CHANGED_FILES" | grep -qv "^docs/\|\.md$"; then
            # Non-documentation changes detected

            # Check for specific feature changes
            if echo "$CHANGED_FILES" | grep -q "^components/features/muednote/\|^app/api/muednote/"; then
              echo "âœ“ MUEDnote feature changes detected (no dedicated E2E tests yet)"
            fi

            if echo "$CHANGED_FILES" | grep -q "^app/dashboard/materials/\|^components/features/materials/"; then
              echo "âœ“ Materials feature changes detected"
              TEST_FILES="$TEST_FILES tests/e2e/materials-sharing-flow.spec.ts tests/e2e/music-material-flow.spec.ts tests/e2e/teacher-workflow.spec.ts"
            fi

            if echo "$CHANGED_FILES" | grep -q "^app/api/"; then
              echo "âœ“ API changes detected"
              TEST_FILES="$TEST_FILES tests/e2e/api-endpoints.spec.ts"
            fi

            if echo "$CHANGED_FILES" | grep -q "^components/layouts/\|^app/layout\.tsx"; then
              echo "âœ“ Layout changes detected"
              TEST_FILES="$TEST_FILES tests/e2e/accessibility.spec.ts"
            fi

            if echo "$CHANGED_FILES" | grep -q "^tests/e2e/"; then
              echo "âœ“ E2E test files changed"
              # Add the specific changed test files
              CHANGED_TEST_FILES=$(echo "$CHANGED_FILES" | grep "^tests/e2e/.*\.spec\.ts$" || true)
              if [ -n "$CHANGED_TEST_FILES" ]; then
                TEST_FILES="$TEST_FILES $CHANGED_TEST_FILES"
              fi
            fi

            # Check for critical changes that require full test suite
            if echo "$CHANGED_FILES" | grep -q "^playwright\.config\.ts\|^package\.json\|^tsconfig\.json\|^next\.config\.js"; then
              echo "âš ï¸  Critical config changes detected - running ALL E2E tests"
              RUN_ALL=true
            fi

            # If no specific tests matched but we have non-doc changes, run all tests (safe default)
            if [ -z "$TEST_FILES" ] && [ "$RUN_ALL" = "false" ]; then
              echo "âš ï¸  No specific test pattern matched - running ALL E2E tests (safe default)"
              RUN_ALL=true
            fi
          else
            echo "â„¹ï¸  Documentation-only changes - skipping all E2E tests"
          fi

          # Remove duplicates and save to output
          if [ "$RUN_ALL" = "true" ]; then
            echo "test_files=ALL" >> $GITHUB_OUTPUT
            echo ""
            echo "ðŸ“‹ Will run: ALL E2E tests"
          elif [ -n "$TEST_FILES" ]; then
            # Remove duplicates
            TEST_FILES=$(echo "$TEST_FILES" | tr ' ' '\n' | sort -u | tr '\n' ' ')
            echo "test_files=$TEST_FILES" >> $GITHUB_OUTPUT
            echo ""
            echo "ðŸ“‹ Will run these test files:"
            echo "$TEST_FILES" | tr ' ' '\n'
          else
            echo "test_files=SKIP" >> $GITHUB_OUTPUT
            echo ""
            echo "ðŸ“‹ Will skip all E2E tests"
          fi

      - name: Run E2E tests (selective)
        if: steps.detect-changes.outputs.test_files != 'SKIP'
        run: |
          if [ "${{ steps.detect-changes.outputs.test_files }}" = "ALL" ]; then
            echo "Running all E2E tests..."
            npm run test:e2e
          else
            echo "Running selected E2E tests..."
            npx playwright test ${{ steps.detect-changes.outputs.test_files }}
          fi
        env:
          CI: true
          NEXT_PUBLIC_E2E_TEST_MODE: true
          # Mock database URL (E2E tests should not need real DB)
          DATABASE_URL: "postgresql://mock:mock@localhost:5432/mock"
          # Clerk test keys (if configured in GitHub secrets)
          NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY: ${{ secrets.CLERK_TEST_PUBLISHABLE_KEY || 'pk_test_mock' }}
          CLERK_SECRET_KEY: ${{ secrets.CLERK_TEST_SECRET_KEY || 'sk_test_mock' }}

      - name: Upload Playwright report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report
          path: playwright-report/
          retention-days: 7

      - name: Upload Playwright videos
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-videos
          path: test-results/
          retention-days: 3

  # ============================================
  # STAGE 5: Accessibility Tests (PR only)
  # ============================================
  a11y:
    name: Accessibility Tests
    if: github.event_name == 'pull_request'
    needs: build
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js with cache
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci --prefer-offline --no-audit
          npm install -D @axe-core/playwright

      - name: Install Playwright browsers
        run: npx playwright install --with-deps chromium

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-output
          path: .

      - name: Extract build artifacts
        run: |
          echo "Extracting build archive..."
          tar -xzf build-output.tar.gz
          rm build-output.tar.gz
          ls -la .next/

      - name: Run accessibility tests
        run: npx playwright test tests/e2e/accessibility.spec.ts
        env:
          CI: true
          NEXT_PUBLIC_E2E_TEST_MODE: true
          DATABASE_URL: "postgresql://mock:mock@localhost:5432/mock"

      - name: Upload accessibility report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: a11y-report
          path: test-results/a11y/
          retention-days: 7

  # ============================================
  # STAGE 6: Quality Checks (non-blocking)
  # ============================================
  quality:
    name: Quality Checks
    needs: validate
    runs-on: ubuntu-latest
    continue-on-error: true
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js with cache
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --prefer-offline --no-audit

      - name: Full ESLint scan
        run: |
          npm run lint || {
            echo "::warning::ESLint found issues - see details above"
            exit 0
          }

      - name: Security audit (production deps)
        run: |
          npm audit --omit=dev --audit-level=moderate || {
            echo "::error::Security vulnerabilities found in production dependencies"
            exit 1
          }

      - name: Security audit (all deps)
        run: |
          npm audit --audit-level=critical || {
            echo "::warning::Security vulnerabilities found in dev dependencies"
            exit 0
          }

  # ============================================
  # STAGE 7: Performance Tests (PR only)
  # ============================================
  performance:
    name: Performance Tests
    if: github.event_name == 'pull_request'
    needs: build
    runs-on: ubuntu-latest
    continue-on-error: true
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js with cache
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-output
          path: .

      - name: Extract build artifacts
        run: |
          echo "Extracting build archive..."
          tar -xzf build-output.tar.gz
          rm build-output.tar.gz
          ls -la .next/

      - name: Run Lighthouse CI
        uses: treosh/lighthouse-ci-action@v10
        with:
          uploadArtifacts: true
          temporaryPublicStorage: true
          runs: 3
        continue-on-error: true

  # ============================================
  # FINAL: CI Status Check (required)
  # ============================================
  ci-status:
    name: CI Status
    needs: [validate, test, build]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Check required jobs
        run: |
          echo "Checking CI pipeline status..."
          echo "Validate: ${{ needs.validate.result }}"
          echo "Test: ${{ needs.test.result }}"
          echo "Build: ${{ needs.build.result }}"

          if [ "${{ needs.validate.result }}" != "success" ] || \
             [ "${{ needs.test.result }}" != "success" ] || \
             [ "${{ needs.build.result }}" != "success" ]; then
            echo "::error::Required CI checks failed"
            exit 1
          fi

          echo "âœ… All required CI checks passed!"

      - name: Create status comment (PR only)
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        continue-on-error: true
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const validate = '${{ needs.validate.result }}' === 'success' ? 'âœ…' : 'âŒ';
            const test = '${{ needs.test.result }}' === 'success' ? 'âœ…' : 'âŒ';
            const build = '${{ needs.build.result }}' === 'success' ? 'âœ…' : 'âŒ';

            const prUrl = '${{ github.event.pull_request.html_url }}';
            const actionsUrl = prUrl.replace('/pull/', '/actions/runs/');

            const comment = `## CI Pipeline Status ðŸ“Š

            ### Required Checks
            | Check | Status |
            |-------|--------|
            | Fast Validation | ${validate} |
            | Unit & Component Tests | ${test} |
            | Build | ${build} |

            ### Optional Checks
            See [Actions tab](${actionsUrl}) for E2E, accessibility, and quality check results.

            ---
            *Generated at ${new Date().toISOString()}*`;

            // Try to update existing comment or create new one
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number
            });

            const botComment = comments.find(c =>
              c.user.type === 'Bot' && c.body.includes('CI Pipeline Status')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }